# first-python-crawler

需求点如下:
"http://b2b.huangye88.com/qiye%s"
这个url是一家企业的介绍,%s是一串数字
1. 需要不断把%s往上加,打印出这串数字和公司名称
3. 公司注册地必须为北京
2. 需要有定时器,不断执行

设计思路:
1. 写一个配置文件,里面存放三个配置项
1) 开始抓取的公司那串数字,可以为1;
2) 步长,往后抓取多少公司,默认100家公司
3) 循环时间,多长时间执行一遍
2. 新建一个文件存放打印的那串数字和公司名称

总结:
学到的知识点如下:
1. ConfigParser对配置文件读取
2. with open() as 这一打开文件方式
3. urllib2对URL的操作
4. 模拟浏览器进行访问
5. 编码的处理,decode&encode
6. re模块的一些方法,如match(),findall()
7. 简单的定时器,while True:  time.sleep()
